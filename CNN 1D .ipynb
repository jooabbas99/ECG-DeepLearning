{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for macbook with AMD GPU\n",
    "import os\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdown --id 11zufpuePYayZys7vK-uFyTOG9_g8o7zv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./../New Folder With Items/MIT_BIH_DATASET_Resampled_Filltered_6_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27200, 301)\n"
     ]
    }
   ],
   "source": [
    "data_new = data.to_numpy()\n",
    "print(data_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27200, 300) (27200,)\n"
     ]
    }
   ],
   "source": [
    "data, labels = data_new[:, :-1], data_new[:, -1]\n",
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biosppy.signals import ecg\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(labels),\n",
    "                                                 labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = float(300)\n",
    "# filter signal\n",
    "order = int(0.3 * sampling_rate)\n",
    "filter_data = np.zeros((len(data),len(data[0])))\n",
    "for i, (xrow, yrow) in enumerate(zip(data, labels)):\n",
    "  filtered, _, _ = ecg.st.filter_signal(signal=xrow,\n",
    "                                      ftype='FIR',\n",
    "                                      band='bandpass',\n",
    "                                      order=order,\n",
    "                                      frequency=[3, 45],\n",
    "                                      sampling_rate=sampling_rate)\n",
    "  # print(filtered)\n",
    "  filter_data[i] = filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(filter_data, labels, test_size=0.40, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(len(X_train), X_train.shape[1],1)\n",
    "X_valid = X_valid.reshape(len(X_valid), X_valid.shape[1],1)\n",
    "X_test = X_test.reshape(len(X_test), X_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(X_train,y_train,X_test,y_test):\n",
    "    im_shape=(X_train.shape[1],1)\n",
    "    inputs_cnn=Input(shape=(im_shape), name='inputs_cnn')\n",
    "    conv1_1=Convolution1D(64, (6), activation='relu', input_shape=im_shape)(inputs_cnn)\n",
    "    conv1_1=BatchNormalization()(conv1_1)\n",
    "    pool1=MaxPool1D(pool_size=(3), strides=(2), padding=\"same\")(conv1_1)\n",
    "    conv2_1=Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool1)\n",
    "    conv2_1=BatchNormalization()(conv2_1)\n",
    "    pool2=MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv2_1)\n",
    "    conv3_1=Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool2)\n",
    "    conv3_1=BatchNormalization()(conv3_1)\n",
    "    pool3=MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv3_1)\n",
    "    flatten=Flatten()(pool3)\n",
    "    dense_end1 = Dense(64, activation='relu')(flatten)\n",
    "    dense_end2 = Dense(32, activation='relu')(dense_end1)\n",
    "    main_output = Dense(5, activation='softmax', name='main_output')(dense_end2)\n",
    "    model = Model(inputs= inputs_cnn, outputs=main_output)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics = ['accuracy'])\n",
    "    mcp_save =keras.callbacks.ModelCheckpoint('./CNN1DbestEpoch.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "    callbacks = [mcp_save]\n",
    "    model.summary()\n",
    "    import tensorflow as tf\n",
    "\n",
    "    tf.keras.utils.plot_model(\n",
    "        model\n",
    "    )\n",
    "\n",
    "    history=model.fit(X_train, y_train,epochs=30,callbacks=callbacks,class_weight=class_weights, batch_size=32,validation_data=(X_test,y_test))\n",
    "    return(model,history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = np.expand_dims(X_train, axis=1)\n",
    "X_valid_ = np.expand_dims(X_valid, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = to_categorical(y_train)\n",
    "y_valid_ = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs_cnn (InputLayer)      (None, 300, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 295, 64)           448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 295, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 148, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 146, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 146, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 73, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 71, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 71, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 36, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 175,685\n",
      "Trainable params: 175,301\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Train on 16320 samples, validate on 5440 samples\n",
      "Epoch 1/30\n",
      "16320/16320 [==============================] - 14s 879us/step - loss: 0.1171 - acc: 0.9642 - val_loss: 0.2050 - val_acc: 0.9316\n",
      "Epoch 2/30\n",
      "16320/16320 [==============================] - 10s 639us/step - loss: 0.0376 - acc: 0.9884 - val_loss: 0.0686 - val_acc: 0.9809\n",
      "Epoch 3/30\n",
      "16320/16320 [==============================] - 10s 637us/step - loss: 0.0243 - acc: 0.9923 - val_loss: 0.0718 - val_acc: 0.9822\n",
      "Epoch 4/30\n",
      "16320/16320 [==============================] - 10s 637us/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0691 - val_acc: 0.9838\n",
      "Epoch 5/30\n",
      "16320/16320 [==============================] - 10s 639us/step - loss: 0.0127 - acc: 0.9961 - val_loss: 0.0775 - val_acc: 0.9835\n",
      "Epoch 6/30\n",
      "16320/16320 [==============================] - 10s 636us/step - loss: 0.0104 - acc: 0.9960 - val_loss: 0.0696 - val_acc: 0.9851\n",
      "Epoch 7/30\n",
      "16320/16320 [==============================] - 10s 608us/step - loss: 0.0108 - acc: 0.9969 - val_loss: 0.0847 - val_acc: 0.9849\n",
      "Epoch 8/30\n",
      "16320/16320 [==============================] - 10s 610us/step - loss: 0.0193 - acc: 0.9946 - val_loss: 0.0950 - val_acc: 0.9812\n",
      "Epoch 9/30\n",
      "16320/16320 [==============================] - 10s 604us/step - loss: 0.0056 - acc: 0.9985 - val_loss: 0.0993 - val_acc: 0.9857\n",
      "Epoch 10/30\n",
      "16320/16320 [==============================] - 10s 604us/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.0758 - val_acc: 0.9897\n",
      "Epoch 11/30\n",
      "16320/16320 [==============================] - 10s 605us/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.1410 - val_acc: 0.9781\n",
      "Epoch 12/30\n",
      "16320/16320 [==============================] - 10s 606us/step - loss: 0.0206 - acc: 0.9945 - val_loss: 0.0909 - val_acc: 0.9866\n",
      "Epoch 13/30\n",
      "16320/16320 [==============================] - 10s 605us/step - loss: 0.0054 - acc: 0.9980 - val_loss: 0.0953 - val_acc: 0.9866\n",
      "Epoch 14/30\n",
      "16320/16320 [==============================] - 10s 605us/step - loss: 0.0055 - acc: 0.9986 - val_loss: 0.0915 - val_acc: 0.9886\n",
      "Epoch 15/30\n",
      "16320/16320 [==============================] - 10s 604us/step - loss: 0.0045 - acc: 0.9991 - val_loss: 0.1095 - val_acc: 0.9851\n",
      "Epoch 16/30\n",
      "16320/16320 [==============================] - 10s 605us/step - loss: 0.0081 - acc: 0.9977 - val_loss: 0.1043 - val_acc: 0.9849\n",
      "Epoch 17/30\n",
      "16320/16320 [==============================] - 10s 605us/step - loss: 0.0079 - acc: 0.9977 - val_loss: 0.1092 - val_acc: 0.9875\n",
      "Epoch 18/30\n",
      "16320/16320 [==============================] - 10s 605us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0824 - val_acc: 0.9904\n",
      "Epoch 19/30\n",
      "16320/16320 [==============================] - 10s 604us/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0894 - val_acc: 0.9892\n",
      "Epoch 20/30\n",
      "16320/16320 [==============================] - 10s 605us/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.0726 - val_acc: 0.9895\n",
      "Epoch 21/30\n",
      "16320/16320 [==============================] - 10s 605us/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0798 - val_acc: 0.9882\n",
      "Epoch 22/30\n",
      "16320/16320 [==============================] - 10s 604us/step - loss: 0.0043 - acc: 0.9984 - val_loss: 0.0966 - val_acc: 0.9890\n",
      "Epoch 23/30\n",
      "16320/16320 [==============================] - 10s 604us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0760 - val_acc: 0.9893\n",
      "Epoch 24/30\n",
      "16320/16320 [==============================] - 10s 605us/step - loss: 0.0031 - acc: 0.9992 - val_loss: 0.0713 - val_acc: 0.9917\n",
      "Epoch 25/30\n",
      "16320/16320 [==============================] - 10s 603us/step - loss: 3.5531e-04 - acc: 0.9999 - val_loss: 0.0699 - val_acc: 0.9890\n",
      "Epoch 26/30\n",
      "16320/16320 [==============================] - 10s 606us/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0831 - val_acc: 0.9875\n",
      "Epoch 27/30\n",
      "16320/16320 [==============================] - 10s 603us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0893 - val_acc: 0.9886\n",
      "Epoch 28/30\n",
      "16320/16320 [==============================] - 10s 605us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.1092 - val_acc: 0.9858\n",
      "Epoch 29/30\n",
      "16320/16320 [==============================] - 10s 603us/step - loss: 0.0100 - acc: 0.9980 - val_loss: 0.1111 - val_acc: 0.9868\n",
      "Epoch 30/30\n",
      "16320/16320 [==============================] - 10s 604us/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.1223 - val_acc: 0.9877\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Convolution1D, MaxPool1D, Flatten, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "model,history=network(X_train,y_train_,X_valid,y_valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = np.expand_dims(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_ = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, y_valid_)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
